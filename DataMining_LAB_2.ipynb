{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7331 Data Mining Lab 2\n",
    "Professor: Dr. Jake Drew  \n",
    "Team: Steven Hayden, Josephine MacDaniel, Korey MacVittie, Afreen Siddiqui, Eduardo Cantu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp1\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DocIndex'></a>\n",
    "### [Data Preparation 1](#DataPrep1)\n",
    "### [Data Preparation 2](#DataPrep2)\n",
    "### [On-Time Evaluation Model](#OnTimeModel)\n",
    "* [Data Split](#DataSplit)\n",
    "* [Logistic Regression](#LogRegMod)\n",
    "* [Decision Tree](#TreeMod)\n",
    "* [K-Nearest Neighbors](#KNNMod)\n",
    "* [Model Comparison for On-Time Variable](#OnTimeComp)    \n",
    "\n",
    "### [Multi-Fatality Accidents](#MultiFatality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataPrep1'></a>\n",
    "### Data Preparation Part 1\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data preperation for model 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "Accident_df_2016 = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/accident_2016.csv',low_memory=False)\n",
    "Accident_df_2015 = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/accident_2015.csv',low_memory=False)\n",
    "Accident_df = pd.concat([Accident_df_2015,Accident_df_2016])\n",
    "\n",
    "\n",
    "#Load Damage Data\n",
    "Distract_df = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/distract.csv',low_memory=False)\n",
    "Damage_df = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/damage.csv',low_memory=False)\n",
    "\n",
    "#Merge the distract data and damage data\n",
    "Accident_df = Accident_df.merge(Distract_df,left_on = 'consecutive_number', right_on = 'consecutive_number', how= 'left')\n",
    "Accident_df = Accident_df.merge(Damage_df,left_on = 'consecutive_number', right_on = 'consecutive_number', how= 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Meaning Type\n",
    "In this section, we will go over the attributes in our data set, and explain each. These descriptions are taken from the kaggle site for this data, found [here](https://www.kaggle.com/usdot/nhtsa-traffic-fatalities).\n",
    "\n",
    "There are quite a few variables here - however, many of them are redundant with each other. As should not be surprising when governmental bureaucracy is involved, there are a variety of variables here that are \"encoded\" and redundant with one another. Much of the information relates to the location of the accident: latitude, longitude, type of roadway, nearest mile marker, type of intersection, and so forth.\n",
    "\n",
    "| Variable Name | Data Type | Description |\n",
    "| :- | :- | :- |\n",
    "| state_number | Interval | Identifies the state in which the crash occurred. The codes are from the General Services Administration’s (GSA) publication of worldwide Geographic Location Codes (GLC). For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| state_name | Nominal | Identifies the state in which the crash occurred. The codes are from the General Services Administration’s (GSA) publication of worldwide Geographic Location Codes (GLC). |\n",
    "| consecutive_number | Interval | Unique case number assigned to each crash. It appears on each data file and is used to merge information from the data files together. xxxxxx Two Characters for State Code followed by Four Characters for Case Number. |\n",
    "| number_of_vehicle_forms_submitted_all | Interval | Count of the total number of vehicles involved. |\n",
    "| number_of_motor_vehicles_in_transport_mvit | Interval | Count of the number of vehicles in-transport involved in the crash. Legally parked vehicles are not included. |\n",
    "| number_of_parked_working_vehicles | Interval | Count of the number of parked and working vehicles involved in the crash. |\n",
    "| number_of_forms_submitted_for_persons_not_in_motor_vehicles | Interval | Number of Person Forms (Not a Motor Vehicle Occupant) that are applicable to this case (i.e., non-occupants). |\n",
    "| number_of_persons_not_in_motor_vehicles_in_transport_mvit | Interval | Count of the number of non-motorists in the crash. A non-motorist is defined as a pedestrian, a cyclist, an occupant of a motor vehicle not intransport, a person riding a horse, an occupant of an animal drawn conveyance, person associated with non-motorist conveyance (e.g., baby carriage, skate board, wheelchair), or an other non-motorist (e.g., person outside a trafficway, person in a house). |\n",
    "| number_of_persons_in_motor_vehicles_in_transport_mvit | Interval | Count of the number of motorists in the crash. A motorist is a driver, passenger or unknown occupant type of a motor vehicle in-transport. |\n",
    "| number_of_forms_submitted_for_persons_in_motor_vehicles | Interval | Count of the number of Person Level (Motor Vehicle Occupant) Forms that are applicable to this case (i.e., occupants). |\n",
    "| county | Nominal | Records the location of the unstabilized event with regard to the County. The codes are from the General Services Administration’s (GSA) publication of worldwide Geographic Location Codes (GLC). |\n",
    "| city | Nominal | Records the location of the unstabilized event with regard to the City. The codes are from the General Services Administration’s (GSA) publication of worldwide Geographic Location Codes (GLC). |\n",
    "| day_of_crash | Ordinal | Records the day of the month on which the crash occurred. |\n",
    "| month_of_crash | Ordinal | Records the month in which the crash occurred. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| year_of_crash | Ordinal | Records the year in which the crash occurred. |\n",
    "| day_of_week | Ordinal | Records the day of the week on which the crash occurred. Sunday is Day 1. |\n",
    "| hour_of_crash | Ordinal | Records the hour at which the crash occurred. Listed in 24-hour format. |\n",
    "| minute_of_crash | Ordinal | Records the minutes after the hour at which the crash occurred. |\n",
    "| national_highway_system | Nominal | Identifies whether this crash occurred on a trafficway that is part of the National Highway System. |\n",
    "| land_use | Nominal | 1 (Rural), 2 (Urban), 6 (Trafficway Not in State Inventory), 8 (Not Reported) and 9 (Unknown). |\n",
    "| land_use_name | Nominal | 1 (Rural), 2 (Urban), 6 (Trafficway Not in State Inventory), 8 (Not Reported) and 9 (Unknown). |\n",
    "| functional_system | Nominal | 01 (Interstate), 02 (Principal Arterial – Other Freeways and Expressways), 03 (Principal Arterial – Other), 04 (Minor Arterial), 05 (Major Collector), 06 (Minor Collector), 07 (Local), 96 (Trafficway Not in State Inventory), 98 (Not Reported), and 99 (Unknown). |\n",
    "| functional_system_name | Nominal | 01 (Interstate), 02 (Principal Arterial – Other Freeways and Expressways), 03 (Principal Arterial – Other), 04 (Minor Arterial), 05 (Major Collector), 06 (Minor Collector), 07 (Local), 96 (Trafficway Not in State Inventory), 98 (Not Reported), and 99 (Unknown). |\n",
    "| ownership | Nominal | For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| ownership_name | Nominal | For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| route_signing | Nominal | Identifies the route signing of the trafficway on which the crash occurred, using a coding system. |\n",
    "| route_signing_name | Nominal | Identifies the route signing of the trafficway on which the crash occurred. |\n",
    "| trafficway_identifier | Nominal | Records the trafficway on which the crash occurred. |\n",
    "| trafficway_identifier_2 | Nominal | Records the trafficway on which the crash occurred. |\n",
    "| milepoint | Interval | Records the milepoint nearest to the location where the crash occurred, if applicable.\n",
    "| latitude | Interval | Identifies the location of the crash using Global Position coordinates. This is the position of latitude. |\n",
    "| longitude | Interval | Identifies the location of the crash using Global Position coordinates. |\n",
    "| special_jurisdiction | Nominal | Identifies if the location on the trafficway where the crash occurred qualifies as a Special Jurisdiction even though it may be patrolled by state, county or local police (e.g., all State highways running through Indian reservations are under the jurisdiction of the Indian reservation). |\n",
    "| special_jurisdiction_name | Nominal | Identifies if the location on the trafficway where the crash occurred qualifies as a Special Jurisdiction even though it may be patrolled by state, county or local police (e.g., all State highways running through Indian reservations are under the jurisdiction of the Indian reservation). |\n",
    "| first_harmful_event | Nominal | Describes the first injury or damage producing event of the crash. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| first_harmful_event_name | Nominal | Describes the first injury or damage producing event of the crash. |\n",
    "| manner_of_collision | Nominal | Describes the orientation of two motor vehicles in-transport when they are involved in the “First Harmful Event” of a collision crash. If the “First Harmful Event” is not a collision between two motor vehicles in-transport it is classified as such. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| manner_of_collision_name | Nominal | Describes the orientation of two motor vehicles in-transport when they are involved in the “First Harmful Event” of a collision crash. If the “First Harmful Event” is not a collision between two motor vehicles in-transport it is classified as such. |\n",
    "| relation_to_junction_within_interchange_area | Nominal | Identifies the crash's location with respect to presence in an interchange area. The coding of this data element is done in two sub-fields (see also C20B) and is based on the location of the “First Harmful Event” of the crash. (0) No (1) Yes (8) Not Reported (9) Unknown |\n",
    "| relation_to_junction_specific_location | Nominal | Identifies the crash's location with respect to presence in or proximity to components typically in junction or interchange areas. The coding of this data element is done in two sub-fields (see also C20A) and is based on the location of the “First Harmful Event” of the crash. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| relation_to_junction_specific_location_name | Nominal | Identifies the crash's location with respect to presence in or proximity to components typically in junction or interchange areas. The coding of this data element is done in two sub-fields (see also C20A) and is based on the location of the “First Harmful Event” of the crash. |\n",
    "| type_of_intersection | Nominal | Identifies and allows separation of various intersection types. (1) Not an Intersection (2) Four-Way Intersection (3) T-Intersection (4) Y-Intersection (5) Traffic Circle (6) Roundabout (7) Five-Point, or More (10) L-Intersection (98) Not Reported (99) Unknown |\n",
    "| work_zone | Nominal | Identifies a motor vehicle traffic crash in which the first harmful event occurs within the boundaries of a work zone or on an approach to or exit from a work zone, resulting from an activity, behavior, or control related to the movement of the traffic units through the work zone. (0) None (1) Construction (2) Maintenance -- Construction or Maintenance (3) Utility (4) Work Zone, Type Unknown (--) Not Reported |\n",
    "| relation_to_trafficway | Nominal | Identifies the location of the crash as it relates to its position within or outside the trafficway based on the “First Harmful Event.” For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| relation_to_trafficway_name | Nominal | Identifies the location of the crash as it relates to its position within or outside the trafficway based on the “First Harmful Event.” |\n",
    "| light_condition | Nominal | Records the type/level of light that existed at the time of the crash as indicated in the case material. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| light_condition_name | Nominal | Records the type/level of light that existed at the time of the crash as indicated in the case material. |\n",
    "| atmospheric_conditions_1 | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| atmospheric_conditions_1_name | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. |\n",
    "| atmospheric_conditions_2 | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| atmospheric_conditions_2_name | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. |\n",
    "| atmospheric_conditions | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| atmospheric_conditions_name | Nominal | Records the prevailing atmospheric conditions that existed at the time of the crash as indicated in the case material. |\n",
    "| school_bus_related | Nominal | Identifies if a school bus, or motor vehicle functioning as a school bus, is related to the crash. (0) No (1) Yes (--) Not Reported |\n",
    "| rail_grade_crossing_identifier | Nominal | Identifies if the crash occurred in or near a rail grade crossing. |\n",
    "| hour_of_notification | Interval | Records the hour that emergency medical service was notified, in 24-hour format. |\n",
    "| minute_of_notification | Interval | Records the minutes after the hour that emergency medical service was notified. |\n",
    "| hour_of_arrival_at_scene | Interval | Records the hour that emergency medical service arrived on the crash scene, in 24-hour format. |\n",
    "| minute_of_arrival_at_scene | Interval | Records the minutes after the hour that emergency medical service arrived on the crash scene. |\n",
    "| hour_of_ems_arrival_at_hospital | Interval | Records the hour that emergency medical service arrived at the treatment facility to which it was transporting victims of the crash, in 24-hour format. |\n",
    "| minute_of_ems_arrival_at_hospital | Interval | Records the minutes after the hour that emergency medical service arrived at the treatment facility to which it was transporting victims of the crash. |\n",
    "| related_factors_crash_level_1 | Nominal | Records factors related to the crash expressed by the investigating officer. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| related_factors_crash_level_1_name | Nominal | Records factors related to the crash expressed by the investigating officer. |\n",
    "| related_factors_crash_level_2 | Nominal | Records factors related to the crash expressed by the investigating officer. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| related_factors_crash_level_2_name | Nominal | Records factors related to the crash expressed by the investigating officer. |\n",
    "| related_factors_crash_level_3 | Nominal | Records factors related to the crash expressed by the investigating officer. For more info on the codes, please look at section in the pdf: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812315 |\n",
    "| related_factors_crash_level_3_name | Nominal | Records factors related to the crash expressed by the investigating officer. |\n",
    "| number_of_fatalities | Interval | Records the number of fatally injured persons in the crash. |\n",
    "| number_of_drunk_drivers | Interval | Records the number of drunk drivers involved in the crash. |\n",
    "| timestamp_of_crash | Nominal | This data element records the date and time on which the crash occurred. |\n",
    "| Clock points | Nominal | Records the count of damage points on the side of the vehicles. |\n",
    "| No Damage | Nominal | Records the count of vehicles with no damage. |\n",
    "| Top | Nominal | Records the count of vehicles with damage on the roof. |\n",
    "| Undercarriage | Nominal | Records the count of vehicles with damage on the undercarriage. |\n",
    "| Unknown | Nominal | Records the count of vehicles with unknow damage on. |\n",
    "| By a Moving Object in Vehicle | Nominal | Count of drivers that were distracted by a moving object in the vehicle. |\n",
    "| By Other Occupant(s) | Nominal | Count of drivers that were distracted by other occupant(s). |\n",
    "| Careless/Inattentive | Nominal | Count of drivers that were careless or inattentive. |\n",
    "| Distracted by Outside Person, Object or Event | Nominal | Count of drivers that were distracted by outside Person, Object or Event |\n",
    "| Distraction (Distracted), Details Unknown | Nominal | Count of drivers that were distracted by a unknown reason. |\n",
    "| Distraction/Inattention | Nominal | Count of drivers that were inattentive. |\n",
    "| Eating or Drinking | Nominal | Count of drivers that were eating or drinking. |\n",
    "| Inattention (Inattentive), Details Unknown | Nominal | count of drivers that were inattentive with unkown details. |\n",
    "| Looked But Did Not See | Nominal | Count of drivers that looked but did not see. |\n",
    "| Lost In Thought/Day Dreaming | Nominal | Count of drivers that lost in thought/day dreaming. |\n",
    "| No Driver Present/Unknown if Driver Present | Nominal | Count of vehicles unknows if driver was present. |\n",
    "| Not Distracted | Nominal | Count of drivers that were not distracted. |\n",
    "| Not Reported | Nominal | Count of vehicles that did not have a distraction reported. |\n",
    "| Other Cellular Phone Related | Nominal | Count of drivers that were distracted related to a cell phone. |\n",
    "| Other Distraction | Nominal | Count of drivers that were distracted due to other circumstances. |\n",
    "| Smoking Related | Nominal | Count of drivers that were distracted due to smoking. |\n",
    "| Unknown if Distracted | Nominal | Count of drivers that were unknow if they were distracted. |\n",
    "| While Adjusting Audio or Climate Controls | Nominal | Count of drivers that were distracted adjusting audio or climate controls. |\n",
    "| While Manipulating Cellular Phone | Nominal | Count of drivers that were distracted manipulating a cell phone. |\n",
    "| While Talking or Listening to Cellular Phone | Nominal | Count of drivers that were distracted due Talking/Listening to a cell phone. |\n",
    "| While Using or Reaching For Device/Object Brought Into Vehicle | Nominal | Count of drivers that were distracted due to using or reaching for device/object. |\n",
    "| While Using Other Component/Controls Integral to Vehicle | Nominal | Count of drivers that were distracted due to using other component/controls integral to vehicle. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66978 entries, 0 to 66977\n",
      "Data columns (total 99 columns):\n",
      "Unnamed: 0                                                        66978 non-null int64\n",
      "state_number                                                      66978 non-null int64\n",
      "state_name                                                        66978 non-null object\n",
      "consecutive_number                                                66978 non-null int64\n",
      "number_of_vehicle_forms_submitted_all                             66978 non-null int64\n",
      "number_of_motor_vehicles_in_transport_mvit                        66978 non-null int64\n",
      "number_of_parked_working_vehicles                                 66978 non-null int64\n",
      "number_of_forms_submitted_for_persons_not_in_motor_vehicles       66978 non-null int64\n",
      "number_of_persons_not_in_motor_vehicles_in_transport_mvit         66978 non-null int64\n",
      "number_of_persons_in_motor_vehicles_in_transport_mvit             66978 non-null int64\n",
      "number_of_forms_submitted_for_persons_in_motor_vehicles           66978 non-null int64\n",
      "county                                                            66978 non-null int64\n",
      "city                                                              66978 non-null int64\n",
      "day_of_crash                                                      66978 non-null int64\n",
      "month_of_crash                                                    66978 non-null int64\n",
      "year_of_crash                                                     66978 non-null int64\n",
      "day_of_week                                                       66978 non-null int64\n",
      "hour_of_crash                                                     66978 non-null int64\n",
      "minute_of_crash                                                   66978 non-null int64\n",
      "national_highway_system                                           66978 non-null int64\n",
      "land_use                                                          66978 non-null int64\n",
      "land_use_name                                                     66978 non-null object\n",
      "functional_system                                                 66978 non-null int64\n",
      "functional_system_name                                            66978 non-null object\n",
      "ownership                                                         66978 non-null int64\n",
      "ownership_name                                                    66978 non-null object\n",
      "route_signing                                                     66978 non-null int64\n",
      "route_signing_name                                                66978 non-null object\n",
      "trafficway_identifier                                             66978 non-null object\n",
      "trafficway_identifier_2                                           17686 non-null object\n",
      "milepoint                                                         66978 non-null int64\n",
      "latitude                                                          66978 non-null float64\n",
      "longitude                                                         66978 non-null float64\n",
      "special_jurisdiction                                              66978 non-null int64\n",
      "special_jurisdiction_name                                         66978 non-null object\n",
      "first_harmful_event                                               66978 non-null int64\n",
      "first_harmful_event_name                                          66978 non-null object\n",
      "manner_of_collision                                               66978 non-null int64\n",
      "manner_of_collision_name                                          66978 non-null object\n",
      "relation_to_junction_within_interchange_area                      66978 non-null object\n",
      "relation_to_junction_specific_location                            66978 non-null int64\n",
      "relation_to_junction_specific_location_name                       66978 non-null object\n",
      "type_of_intersection                                              66978 non-null object\n",
      "work_zone                                                         66978 non-null object\n",
      "relation_to_trafficway                                            66978 non-null int64\n",
      "relation_to_trafficway_name                                       66978 non-null object\n",
      "light_condition                                                   66978 non-null int64\n",
      "light_condition_name                                              66978 non-null object\n",
      "atmospheric_conditions_1                                          66978 non-null int64\n",
      "atmospheric_conditions_1_name                                     66978 non-null object\n",
      "atmospheric_conditions_2                                          66978 non-null int64\n",
      "atmospheric_conditions_2_name                                     66978 non-null object\n",
      "atmospheric_conditions                                            66978 non-null int64\n",
      "atmospheric_conditions_name                                       66978 non-null object\n",
      "school_bus_related                                                66978 non-null object\n",
      "rail_grade_crossing_identifier                                    66978 non-null object\n",
      "hour_of_notification                                              66978 non-null int64\n",
      "minute_of_notification                                            66978 non-null int64\n",
      "hour_of_arrival_at_scene                                          66978 non-null int64\n",
      "minute_of_arrival_at_scene                                        66978 non-null int64\n",
      "hour_of_ems_arrival_at_hospital                                   66978 non-null int64\n",
      "minute_of_ems_arrival_at_hospital                                 66978 non-null int64\n",
      "related_factors_crash_level_1                                     66978 non-null int64\n",
      "related_factors_crash_level_1_name                                66978 non-null object\n",
      "related_factors_crash_level_2                                     66978 non-null int64\n",
      "related_factors_crash_level_2_name                                66978 non-null object\n",
      "related_factors_crash_level_3                                     66978 non-null int64\n",
      "related_factors_crash_level_3_name                                66978 non-null object\n",
      "number_of_fatalities                                              66978 non-null int64\n",
      "number_of_drunk_drivers                                           66978 non-null int64\n",
      "timestamp_of_crash                                                66978 non-null object\n",
      "By a Moving Object in Vehicle                                     66963 non-null float64\n",
      "By Other Occupant(s)                                              66963 non-null float64\n",
      "Careless/Inattentive                                              66963 non-null float64\n",
      "Distracted by Outside Person, Object or Event                     66963 non-null float64\n",
      "Distraction (Distracted), Details Unknown                         66963 non-null float64\n",
      "Distraction/Careless                                              66963 non-null float64\n",
      "Distraction/Inattention                                           66963 non-null float64\n",
      "Eating or Drinking                                                66963 non-null float64\n",
      "Inattention (Inattentive), Details Unknown                        66963 non-null float64\n",
      "Looked But Did Not See                                            66963 non-null float64\n",
      "Lost In Thought/Day Dreaming                                      66963 non-null float64\n",
      "No Driver Present/Unknown if Driver Present                       66963 non-null float64\n",
      "Not Distracted                                                    66963 non-null float64\n",
      "Not Reported                                                      66963 non-null float64\n",
      "Other Cellular Phone Related                                      66963 non-null float64\n",
      "Other Distraction                                                 66963 non-null float64\n",
      "Smoking Related                                                   66963 non-null float64\n",
      "Unknown if Distracted                                             66963 non-null float64\n",
      "While Adjusting Audio or Climate Controls                         66963 non-null float64\n",
      "While Manipulating Cellular Phone                                 66963 non-null float64\n",
      "While Talking or Listening to Cellular Phone                      66963 non-null float64\n",
      "While Using or Reaching For Device/Object Brought Into Vehicle    66963 non-null float64\n",
      "While Using Other Component/Controls Integral to Vehicle          66963 non-null float64\n",
      "Clock points                                                      65958 non-null float64\n",
      "No Damage                                                         65958 non-null float64\n",
      "Top                                                               65958 non-null float64\n",
      "Undercarriage                                                     65958 non-null float64\n",
      "Unknown                                                           65958 non-null float64\n",
      "dtypes: float64(30), int64(44), object(25)\n",
      "memory usage: 51.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Displays the record count of non-null Values per attribute and their data type. \n",
    "Accident_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplicate Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape before duplicate Removal: (66978, 99)\n"
     ]
    }
   ],
   "source": [
    "#Print shape before duplicate removal\n",
    "print(\"Data Shape before duplicate Removal:\", Accident_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate records. It displays the maximum count of a duplicated record. \n",
    "#Any value greater than 1 would mean that the data has duplicates\n",
    "Accident_df['consecutive_number'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop duplicate records and keeps the most recent record. We assume the most resent is the most accurate \n",
    "Accident_df = Accident_df.drop_duplicates(['consecutive_number'],keep = 'last')\n",
    "\n",
    "#check for duplicate records. It displays the maximum count of a duplicated record . \n",
    "#Any value greater than 1 would mean that the data has duplicates\n",
    "Accident_df['consecutive_number'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape After duplicate Removal: (35379, 99)\n"
     ]
    }
   ],
   "source": [
    "#Print shape After duplicate removal\n",
    "print(\"Data Shape After duplicate Removal:\", Accident_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                             35379\n",
       "Unnamed: 0                                                        35379\n",
       "state_number                                                      35379\n",
       "state_name                                                        35379\n",
       "consecutive_number                                                35379\n",
       "number_of_vehicle_forms_submitted_all                             35379\n",
       "number_of_motor_vehicles_in_transport_mvit                        35379\n",
       "number_of_parked_working_vehicles                                 35379\n",
       "number_of_forms_submitted_for_persons_not_in_motor_vehicles       35379\n",
       "number_of_persons_not_in_motor_vehicles_in_transport_mvit         35379\n",
       "number_of_persons_in_motor_vehicles_in_transport_mvit             35379\n",
       "number_of_forms_submitted_for_persons_in_motor_vehicles           35379\n",
       "county                                                            35379\n",
       "city                                                              35379\n",
       "day_of_crash                                                      35379\n",
       "month_of_crash                                                    35379\n",
       "year_of_crash                                                     35379\n",
       "day_of_week                                                       35379\n",
       "hour_of_crash                                                     35379\n",
       "minute_of_crash                                                   35379\n",
       "national_highway_system                                           35379\n",
       "land_use                                                          35379\n",
       "land_use_name                                                     35379\n",
       "functional_system                                                 35379\n",
       "functional_system_name                                            35379\n",
       "ownership                                                         35379\n",
       "ownership_name                                                    35379\n",
       "route_signing                                                     35379\n",
       "route_signing_name                                                35379\n",
       "trafficway_identifier                                             35379\n",
       "                                                                  ...  \n",
       "number_of_drunk_drivers                                           35379\n",
       "timestamp_of_crash                                                35379\n",
       "By a Moving Object in Vehicle                                     35364\n",
       "By Other Occupant(s)                                              35364\n",
       "Careless/Inattentive                                              35364\n",
       "Distracted by Outside Person, Object or Event                     35364\n",
       "Distraction (Distracted), Details Unknown                         35364\n",
       "Distraction/Careless                                              35364\n",
       "Distraction/Inattention                                           35364\n",
       "Eating or Drinking                                                35364\n",
       "Inattention (Inattentive), Details Unknown                        35364\n",
       "Looked But Did Not See                                            35364\n",
       "Lost In Thought/Day Dreaming                                      35364\n",
       "No Driver Present/Unknown if Driver Present                       35364\n",
       "Not Distracted                                                    35364\n",
       "Not Reported                                                      35364\n",
       "Other Cellular Phone Related                                      35364\n",
       "Other Distraction                                                 35364\n",
       "Smoking Related                                                   35364\n",
       "Unknown if Distracted                                             35364\n",
       "While Adjusting Audio or Climate Controls                         35364\n",
       "While Manipulating Cellular Phone                                 35364\n",
       "While Talking or Listening to Cellular Phone                      35364\n",
       "While Using or Reaching For Device/Object Brought Into Vehicle    35364\n",
       "While Using Other Component/Controls Integral to Vehicle          35364\n",
       "Clock points                                                      34401\n",
       "No Damage                                                         34401\n",
       "Top                                                               34401\n",
       "Undercarriage                                                     34401\n",
       "Unknown                                                           34401\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays all the available attributes on the dataset\n",
    "Accident_df=Accident_df.reset_index()\n",
    "Accident_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type Colunm Count\n",
    "This will look into the number of attributes per variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnType</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>float64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ColumnType  Count\n",
       "0      int64     45\n",
       "1    float64     30\n",
       "2     object     25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look a at the data type on the Merged Data\n",
    "dtype_df=Accident_df.dtypes.reset_index()\n",
    "dtype_df.columns=[\"Count\",\"ColumnType\"]\n",
    "dtype_df.groupby(\"ColumnType\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>51</td>\n",
       "      <td>Texas</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land_use_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>5</td>\n",
       "      <td>Rural</td>\n",
       "      <td>17181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional_system_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>10</td>\n",
       "      <td>Principal Arterial – Other</td>\n",
       "      <td>10396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ownership_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>25</td>\n",
       "      <td>State Highway Agency</td>\n",
       "      <td>18486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_signing_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>9</td>\n",
       "      <td>State Highway</td>\n",
       "      <td>10498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trafficway_identifier</th>\n",
       "      <td>35379</td>\n",
       "      <td>16928</td>\n",
       "      <td>I-10</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trafficway_identifier_2</th>\n",
       "      <td>9432</td>\n",
       "      <td>8138</td>\n",
       "      <td>MAIN ST</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_jurisdiction_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>7</td>\n",
       "      <td>No Special Jurisdiction (Includes National For...</td>\n",
       "      <td>34974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_harmful_event_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>51</td>\n",
       "      <td>Motor Vehicle in Transport</td>\n",
       "      <td>13432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manner_of_collision_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>11</td>\n",
       "      <td>Not Collision with Motor Vehicle in Transport ...</td>\n",
       "      <td>21900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation_to_junction_within_interchange_area</th>\n",
       "      <td>35379</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>33829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation_to_junction_specific_location_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>15</td>\n",
       "      <td>Non-Junction</td>\n",
       "      <td>24027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_of_intersection</th>\n",
       "      <td>35379</td>\n",
       "      <td>9</td>\n",
       "      <td>Not an Intersection</td>\n",
       "      <td>26626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_zone</th>\n",
       "      <td>35379</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>34682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation_to_trafficway_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>12</td>\n",
       "      <td>On Roadway</td>\n",
       "      <td>21348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light_condition_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>9</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>16759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atmospheric_conditions_1_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>13</td>\n",
       "      <td>Clear</td>\n",
       "      <td>25263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atmospheric_conditions_2_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>13</td>\n",
       "      <td>No Additional Atmospheric Conditions</td>\n",
       "      <td>35009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atmospheric_conditions_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>13</td>\n",
       "      <td>Clear</td>\n",
       "      <td>25257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_bus_related</th>\n",
       "      <td>35379</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>35270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rail_grade_crossing_identifier</th>\n",
       "      <td>35379</td>\n",
       "      <td>118</td>\n",
       "      <td>0000000</td>\n",
       "      <td>35248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related_factors_crash_level_1_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>33004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related_factors_crash_level_2_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>35014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related_factors_crash_level_3_name</th>\n",
       "      <td>35379</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>35185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_of_crash</th>\n",
       "      <td>35379</td>\n",
       "      <td>33660</td>\n",
       "      <td>2016-11-13 00:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              count unique  \\\n",
       "state_name                                    35379     51   \n",
       "land_use_name                                 35379      5   \n",
       "functional_system_name                        35379     10   \n",
       "ownership_name                                35379     25   \n",
       "route_signing_name                            35379      9   \n",
       "trafficway_identifier                         35379  16928   \n",
       "trafficway_identifier_2                        9432   8138   \n",
       "special_jurisdiction_name                     35379      7   \n",
       "first_harmful_event_name                      35379     51   \n",
       "manner_of_collision_name                      35379     11   \n",
       "relation_to_junction_within_interchange_area  35379      4   \n",
       "relation_to_junction_specific_location_name   35379     15   \n",
       "type_of_intersection                          35379      9   \n",
       "work_zone                                     35379      5   \n",
       "relation_to_trafficway_name                   35379     12   \n",
       "light_condition_name                          35379      9   \n",
       "atmospheric_conditions_1_name                 35379     13   \n",
       "atmospheric_conditions_2_name                 35379     13   \n",
       "atmospheric_conditions_name                   35379     13   \n",
       "school_bus_related                            35379      2   \n",
       "rail_grade_crossing_identifier                35379    118   \n",
       "related_factors_crash_level_1_name            35379     25   \n",
       "related_factors_crash_level_2_name            35379     20   \n",
       "related_factors_crash_level_3_name            35379      9   \n",
       "timestamp_of_crash                            35379  33660   \n",
       "\n",
       "                                                                                            top  \\\n",
       "state_name                                                                                Texas   \n",
       "land_use_name                                                                             Rural   \n",
       "functional_system_name                                               Principal Arterial – Other   \n",
       "ownership_name                                                             State Highway Agency   \n",
       "route_signing_name                                                                State Highway   \n",
       "trafficway_identifier                                                                      I-10   \n",
       "trafficway_identifier_2                                                                 MAIN ST   \n",
       "special_jurisdiction_name                     No Special Jurisdiction (Includes National For...   \n",
       "first_harmful_event_name                                             Motor Vehicle in Transport   \n",
       "manner_of_collision_name                      Not Collision with Motor Vehicle in Transport ...   \n",
       "relation_to_junction_within_interchange_area                                                 No   \n",
       "relation_to_junction_specific_location_name                                        Non-Junction   \n",
       "type_of_intersection                                                        Not an Intersection   \n",
       "work_zone                                                                                  None   \n",
       "relation_to_trafficway_name                                                          On Roadway   \n",
       "light_condition_name                                                                   Daylight   \n",
       "atmospheric_conditions_1_name                                                             Clear   \n",
       "atmospheric_conditions_2_name                              No Additional Atmospheric Conditions   \n",
       "atmospheric_conditions_name                                                               Clear   \n",
       "school_bus_related                                                                           No   \n",
       "rail_grade_crossing_identifier                                                          0000000   \n",
       "related_factors_crash_level_1_name                                                         None   \n",
       "related_factors_crash_level_2_name                                                         None   \n",
       "related_factors_crash_level_3_name                                                         None   \n",
       "timestamp_of_crash                                                    2016-11-13 00:00:00+00:00   \n",
       "\n",
       "                                               freq  \n",
       "state_name                                     3495  \n",
       "land_use_name                                 17181  \n",
       "functional_system_name                        10396  \n",
       "ownership_name                                18486  \n",
       "route_signing_name                            10498  \n",
       "trafficway_identifier                           312  \n",
       "trafficway_identifier_2                          26  \n",
       "special_jurisdiction_name                     34974  \n",
       "first_harmful_event_name                      13432  \n",
       "manner_of_collision_name                      21900  \n",
       "relation_to_junction_within_interchange_area  33829  \n",
       "relation_to_junction_specific_location_name   24027  \n",
       "type_of_intersection                          26626  \n",
       "work_zone                                     34682  \n",
       "relation_to_trafficway_name                   21348  \n",
       "light_condition_name                          16759  \n",
       "atmospheric_conditions_1_name                 25263  \n",
       "atmospheric_conditions_2_name                 35009  \n",
       "atmospheric_conditions_name                   25257  \n",
       "school_bus_related                            35270  \n",
       "rail_grade_crossing_identifier                35248  \n",
       "related_factors_crash_level_1_name            33004  \n",
       "related_factors_crash_level_2_name            35014  \n",
       "related_factors_crash_level_3_name            35185  \n",
       "timestamp_of_crash                                5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Categorical Objects\n",
    "list_include = ['object']\n",
    "Accident_df.describe(include=list_include).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Histograms for the unbalanced attributes\n",
    "#for col in ['school_bus_related','special_jurisdiction_name','special_jurisdiction_name','relation_to_junction_within_interchange_area',\n",
    "#           'work_zone','atmospheric_conditions_2_name','rail_grade_crossing_identifier','related_factors_crash_level_1_name','related_factors_crash_level_2_name',\n",
    "#           'related_factors_crash_level_3_name']:\n",
    "\n",
    "from matplotlib.ticker import NullFormatter  # useful for `logit` scale\n",
    "list_include = ['object']\n",
    "i=1\n",
    "for col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "    if col not in ['trafficway_identifier','trafficway_identifier_2','timestamp_of_crash']:\n",
    "        if i<=3:\n",
    "            #plt.figure(figsize=(10,4))\n",
    "            plt.subplot(1,3,i)\n",
    "            plt.hist(Accident_df[col], bins=len(Accident_df[col].unique()))\n",
    "            plt.title(col,size=7.8)\n",
    "            plt.xlabel('Class', size=5)\n",
    "            plt.ylabel('Class frequency', size=7)\n",
    "            plt.xticks(rotation='vertical', size=4)\n",
    "            plt.yticks(size=7)\n",
    "            i=i+1\n",
    "        else:\n",
    "            plt.subplots_adjust(top=.7, bottom=0.4, left=0.01, right=1.1, hspace=0.25, wspace=2)\n",
    "            plt.show()\n",
    "            i = 1\n",
    "\n",
    "plt.subplots_adjust(top=.7, bottom=0.4, left=0.01, right=1.1, hspace=0.25, wspace=2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are attritbutes that show extreme imbalance in the dataset. These attributes do not add value to the prediction since most the values are the same. Also, when doing cross validation there is a high probaility that the test set only chooses the highest class.\n",
    "\n",
    "**Imbalance Attributes:**  \n",
    "* school_bus_related  \n",
    "* special_jurisdiction_name\n",
    "* relation_to_junction_within_interchange_area\n",
    "* work_zone\n",
    "* atmospheric_conditions_1_name\n",
    "* atmospheric_conditions_2_name\n",
    "* rail_grade_crossing_identifier\n",
    "* related_factors_crash_level_1_name\n",
    "* related_factors_crash_level_2_name\n",
    "* related_factors_crash_level_3_name\n",
    "* trafficway_identifier\n",
    "* trafficway_identifier_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class analysis\n",
    " This will look into the classes per attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class analysis\n",
    "list_include = ['object']\n",
    "unique_values_dict = {}\n",
    "for col in Accident_df.columns:\n",
    "    if col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "        unique_value = str(Accident_df[col].unique())\n",
    "        tlist = unique_values_dict.get(unique_value, [])\n",
    "        tlist.append(col)\n",
    "        unique_values_dict[unique_value] = tlist[:]\n",
    "for unique_val, columns in unique_values_dict.items():\n",
    "    print(\"Columns containing the unique values : \",unique_val)\n",
    "    print(columns)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the Float Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Float Objects\n",
    "list_include = ['float64']\n",
    "Accident_df.describe(include=list_include).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all float values\n",
    "list_include = ['float64']\n",
    "i=1\n",
    "for col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "    if i<=3:\n",
    "        #plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,3,i)\n",
    "        plt.scatter(range(Accident_df.shape[0]),np.sort(Accident_df[col].values))\n",
    "        plt.xlabel('Index', size=5)\n",
    "        plt.title(col, size=7)\n",
    "        plt.ylabel('Class frequency', size=7)\n",
    "        plt.xticks(size=7)\n",
    "        i = i + 1\n",
    "    else:\n",
    "        plt.subplots_adjust(top=.7, bottom=0.4, left=0.01, right=1.1, hspace=0.25, wspace=2)\n",
    "        plt.show()\n",
    "        i = 1\n",
    "plt.subplots_adjust(top=.7, bottom=0.4, left=0.01, right=1.1, hspace=0.25, wspace=2)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary classes in Float:**\n",
    "* By a Moving Object in Vehicle\n",
    "* By Other Occupant(s)\t\n",
    "* Careless/Inattentive\n",
    "* Distraction/Careless\n",
    "* Eating or Drinking\n",
    "* Lost In Thought/Day Dreaming\n",
    "* Smoking Related\n",
    "* While Adjusting Audio or Climate Controls\n",
    "* While Manipulating Cellular Phone\n",
    "* While Talking or Listening to Cellular Phone\n",
    "* While Using or Reaching For Device/Object Brought Into Vehicle\n",
    "* While Using Other Component/Controls Integral to Vehicle\n",
    "\n",
    "**Float Classes that can be integers**\n",
    "* Distracted by Outside Person, Object or Event\n",
    "* Distraction (Distracted), Details Unknown\n",
    "* Distraction/Inattention\n",
    "* Inattention (Inattentive), Details Unknown\n",
    "* Looked But Did Not See \n",
    "* No Driver Present/Unknown if Driver Present\n",
    "* Not Distracted\n",
    "* Not Reported\n",
    "* Other Cellular Phone Related\n",
    "* Other Distraction\n",
    "* Unknown if Distracted\t\n",
    "* Clock points\n",
    "* No Damage\n",
    "* Top\n",
    "* Undercarriage\n",
    "* Unknown\n",
    "\n",
    "The only true float class is the **Fatalities_ratio, latitude, and longitude**, all other classes can be converted to integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Per Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "missing_df=Accident_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns=['ColumnName','MissingCount']\n",
    "missing_df=missing_df.ix[missing_df['MissingCount']>0]\n",
    "missing_df=missing_df.sort_values(by='MissingCount')\n",
    "\n",
    "missing_df = missing_df.merge(dtype_df,left_on = 'ColumnName', right_on = 'Count', how= 'left')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_include = ['float64']\n",
    "# Add a 99 to all float missing values. 99 would mean that it was NA before. This has to be done in order to change the data type to integer.\n",
    "# There is still a need to know what to do with these observations.\n",
    "for col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "    if col not in ['Fatalities_ratio']:\n",
    "        Accident_df[col].fillna(value=99, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review Missing Values after adding value '99' to all the missing values in the above attributes. As expected only the Traffic_indentifier_2 still show 12,111 null values. Therefore, this attribute would be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review missing Values Again.\n",
    "# Missing Values\n",
    "missing_df=Accident_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns=['ColumnName','MissingCount']\n",
    "missing_df=missing_df.ix[missing_df['MissingCount']>0]\n",
    "missing_df=missing_df.sort_values(by='MissingCount')\n",
    "\n",
    "missing_df = missing_df.merge(dtype_df,left_on = 'ColumnName', right_on = 'Count', how= 'left')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_include = ['float64']\n",
    "# Convert all floats into integers except for 'Fatalities_ratio'\n",
    "for col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "    if col not in ['Fatalities_ratio','latitude','longitude']:\n",
    "        Accident_df[col] = Accident_df[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the datatype again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look a at the data type on the Merged Data\n",
    "dtype_df=Accident_df.dtypes.reset_index()\n",
    "dtype_df.columns=[\"Count\",\"ColumnType\"]\n",
    "dtype_df.groupby(\"ColumnType\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the Integer Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Integer Objects\n",
    "list_include = ['int64','int32']\n",
    "Accident_df.describe(include=list_include).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the integer unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Integer analysis\n",
    "list_include = ['int64','int32']\n",
    "unique_values_dict = {}\n",
    "for col in Accident_df.columns:\n",
    "    if col in Accident_df.select_dtypes(include=list_include).columns:\n",
    "        unique_value = str(np.sort(Accident_df[col].unique()).tolist())\n",
    "        tlist = unique_values_dict.get(unique_value, [])\n",
    "        tlist.append(col)\n",
    "        unique_values_dict[unique_value] = tlist[:]\n",
    "for unique_val, columns in unique_values_dict.items():\n",
    "    print(\"Columns containing the unique values : \",unique_val)\n",
    "    print(columns)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes that do not add any value to predict the paramedict on time response.\n",
    "\n",
    "* Unnamed: 0\n",
    "* consecutive_number\n",
    "* milepoint\n",
    "* latitude\n",
    "* longitude\n",
    "* hour_of_ems_arrival_at_hospital\n",
    "* minute_of_ems_arrival_at_hospital\n",
    "* Clock points\n",
    "* Unknown\n",
    "* Response_Time\n",
    "\n",
    "Attributes that have an associated name to its ordinal value. The atribute with the name would be kept.\n",
    "* atmospheric_conditions\n",
    "* atmospheric_conditions_1\n",
    "* atmospheric_conditions_2\n",
    "* state_number\n",
    "\n",
    "The majority of the values are null.\n",
    "\n",
    "* trafficway_identifier_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data for Task 2 before any manipulation \n",
    "Accident_df_2 = Accident_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataPrep2'></a>\n",
    "### Data Preparation Part 2 for Within NFPA standard Models\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many accidents with missing data regarding the crash time and the arrival time of responders. This information is necessary for the dependent variable, and in turn is crucial for our analysis. That is why we decided to drop these records with missing data, instead of imputing the gaps with the mean. The amount of records dropped is about a third of the original data set, but we have sufficient records that this should not prove to be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any recoreds without  time informaiton for arival and crash time\n",
    "count_no_rec= Accident_df[(Accident_df['hour_of_crash']>24) | (Accident_df['hour_of_arrival_at_scene']>24)]\n",
    "Accident_df = Accident_df[(Accident_df['hour_of_crash']<=24) & (Accident_df['hour_of_arrival_at_scene']<=24)]\n",
    "print(count_no_rec.consecutive_number.count(), 'records were removed due to missing time data.') \n",
    "print(\"Data Shape After time record Removal:\", Accident_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new Feature. This is the ratio between the number of fatalities and the people involved in the accident.\n",
    "Accident_df['Fatalities_ratio'] = Accident_df.number_of_fatalities/(Accident_df.number_of_persons_not_in_motor_vehicles_in_transport_mvit + Accident_df.number_of_persons_in_motor_vehicles_in_transport_mvit)\n",
    "\n",
    "#Converts hour and min to datetime type\n",
    "#crash\n",
    "Accident_df.hour_of_crash = pd.to_timedelta(Accident_df.hour_of_crash,unit ='h')\n",
    "Accident_df.minute_of_crash= pd.to_timedelta(Accident_df.minute_of_crash,unit ='m')\n",
    "#arrival\n",
    "Accident_df.hour_of_arrival_at_scene = pd.to_timedelta(Accident_df.hour_of_arrival_at_scene,unit ='h')\n",
    "Accident_df.minute_of_arrival_at_scene = pd.to_timedelta(Accident_df.minute_of_arrival_at_scene,unit ='m')\n",
    "\n",
    "#concatenates Hour and Minutes together \n",
    "Accident_df['Crash_Time'] = Accident_df['hour_of_crash'] + Accident_df['minute_of_crash'] \n",
    "Accident_df['Arrival_Time'] = Accident_df['hour_of_arrival_at_scene'] + Accident_df['minute_of_arrival_at_scene']\n",
    "#creates a response_time variable from the two fields above and converts to min\n",
    "Accident_df['Response_Time'] = Accident_df['Arrival_Time'] - Accident_df['Crash_Time']\n",
    "total_response_time_in_min = pd.DatetimeIndex(Accident_df['Response_Time'])\n",
    "Accident_df['Response_Time']= total_response_time_in_min.hour * 60 + total_response_time_in_min.minute\n",
    "\n",
    "\n",
    "#gut check of calculation \n",
    "Accident_df[['hour_of_crash','minute_of_crash','Crash_Time','hour_of_arrival_at_scene','minute_of_arrival_at_scene','Arrival_Time','Response_Time']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Fire Protection Association (NFPA) has established a standard for response time and procedures for Emergency Medical Services (EMS) to adhere to.\n",
    "\n",
    "From EMSword.com, \"The NFPA 1710 standard is based upon a combination of accepted practices and more than 30 years of study, research, testing and validation. Members of the 1710 committee that developed the standard include representatives from various fire agencies and the International Association of City/County Managers (ICMA).\"\n",
    "\n",
    "The NFPA 1710 standard allows for a one-minute call for evaluation and preparation, and four minutes for the arrival of a unit with first responders. For a situation that requires advanced life support equipment, such as an ambulance, the standard is eight minutes after call preparation.  \n",
    "\n",
    "We chose to use their standards as a threshold to determine if paramedics got to the scene of the accident \"in time.\" This would be a binary response of \"0\" for not arriving within 9 minutes of the accident, with \"1\" representing being within the 9 minutes. \n",
    "\n",
    "Source: https://www.emsworld.com/article/10324786/ems-response-time-standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the binary variable 'within 9 minutes NFPA standard'\n",
    "Accident_df['within 9 minutes NFPA standard'] = np.where(Accident_df['Response_Time']<=9,1,0)\n",
    "#Accident_df[['Response_Time','within 9 minutes NFPA standard']].head(10) # Verify the binary variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the logistic regression will predict if the paramedics arrived to the scene of the accident within the target window, we would select the attributes that we think affect this variable. Generally, we suspect that weather conditions, type of road, and state may play a role.\n",
    "First we would check what columns are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the attributes in the dataset, we will select a subset to predict whether or not emergency responders would respond within the target window.\n",
    "\n",
    "* **state_name:** Due to differences in size and funding, it is possible that the state in which an accident occurs may play a role.\n",
    "* **route_signing_name:** The type of roadway will probably play a role, as some road types may cover areas that are more distant from dispatch locations.\n",
    "* **light_condition_name:** The local lighting would certainly seem to be important in determining if responders are able to respond in time: darkness is more dangerous to drive in than light.\n",
    "* **atmospheric_conditions_name:** Weather conditions will almost certainly play a role.\n",
    "* **within 9 minutes NFPA standard:** Our response variable. A 1 indicates that emergency services responded within the target window, which is 9 minutes. A 0 indicates that responders arrived outside the target window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the original Data\n",
    "Accident_for_Model=Accident_df.copy()\n",
    "\n",
    "# 1. Remove attributes that just arent useful for us\n",
    "for col in ['Unnamed: 0',\n",
    "             'state_number',\n",
    "             'consecutive_number',\n",
    "             'county',\n",
    "             'city',\n",
    "             'day_of_crash',\n",
    "             'month_of_crash',\n",
    "             'year_of_crash',\n",
    "             'day_of_week',\n",
    "             'hour_of_crash',\n",
    "             'minute_of_crash',\n",
    "             'national_highway_system',\n",
    "             'land_use',\n",
    "             'land_use_name',\n",
    "             'functional_system',\n",
    "             'functional_system_name',\n",
    "             'ownership',\n",
    "             'ownership_name',\n",
    "             'route_signing',\n",
    "             'trafficway_identifier',\n",
    "             'trafficway_identifier_2',\n",
    "             'latitude',\n",
    "             'longitude',\n",
    "             'special_jurisdiction',\n",
    "             'special_jurisdiction_name',\n",
    "             'first_harmful_event',\n",
    "             'first_harmful_event_name',\n",
    "             'manner_of_collision',\n",
    "             'manner_of_collision_name',\n",
    "             'relation_to_junction_within_interchange_area',\n",
    "             'relation_to_junction_specific_location',\n",
    "             'relation_to_junction_specific_location_name',\n",
    "             'type_of_intersection',\n",
    "             'work_zone',\n",
    "             'relation_to_trafficway',\n",
    "             'relation_to_trafficway_name',\n",
    "             'light_condition',\n",
    "             'atmospheric_conditions_1',\n",
    "             'atmospheric_conditions_1_name',\n",
    "             'atmospheric_conditions_2',\n",
    "             'atmospheric_conditions_2_name',\n",
    "             'atmospheric_conditions',\n",
    "             'school_bus_related',\n",
    "             'rail_grade_crossing_identifier',\n",
    "             'hour_of_notification',\n",
    "             'minute_of_notification',\n",
    "             'hour_of_arrival_at_scene',\n",
    "             'minute_of_arrival_at_scene',\n",
    "             'hour_of_ems_arrival_at_hospital',\n",
    "             'minute_of_ems_arrival_at_hospital',\n",
    "             'related_factors_crash_level_1',\n",
    "             'related_factors_crash_level_1_name',\n",
    "             'related_factors_crash_level_2',\n",
    "             'related_factors_crash_level_2_name',\n",
    "             'related_factors_crash_level_3',\n",
    "             'related_factors_crash_level_3_name',\n",
    "             'milepoint',\n",
    "             'number_of_parked_working_vehicles',\n",
    "             'number_of_forms_submitted_for_persons_not_in_motor_vehicles',\n",
    "             'number_of_persons_not_in_motor_vehicles_in_transport_mvit',\n",
    "             'number_of_persons_in_motor_vehicles_in_transport_mvit',\n",
    "             'number_of_forms_submitted_for_persons_in_motor_vehicles',\n",
    "             'timestamp_of_crash',\n",
    "             'number_of_fatalities',\n",
    "             'number_of_drunk_drivers',\n",
    "             'Fatalities_ratio',\n",
    "             'number_of_vehicle_forms_submitted_all',\n",
    "             'Crash_Time',\n",
    "             'Arrival_Time',\n",
    "             'Response_Time',\n",
    "             'number_of_motor_vehicles_in_transport_mvit',\n",
    "             'By a Moving Object in Vehicle',\n",
    "             'By Other Occupant(s)',\n",
    "             'Careless/Inattentive',\n",
    "             'Distracted by Outside Person, Object or Event',\n",
    "             'Distraction (Distracted), Details Unknown',\n",
    "             'Distraction/Careless',\n",
    "             'Distraction/Inattention',\n",
    "             'Eating or Drinking',\n",
    "             'Inattention (Inattentive), Details Unknown',\n",
    "             'Looked But Did Not See',\n",
    "             'Lost In Thought/Day Dreaming',\n",
    "             'No Driver Present/Unknown if Driver Present',\n",
    "             'Not Distracted',\n",
    "             'Not Reported',\n",
    "             'Other Cellular Phone Related',\n",
    "             'Other Distraction',\n",
    "             'Smoking Related',\n",
    "             'Unknown if Distracted',\n",
    "             'While Adjusting Audio or Climate Controls',\n",
    "             'While Manipulating Cellular Phone',\n",
    "             'While Talking or Listening to Cellular Phone',\n",
    "             'While Using or Reaching For Device/Object Brought Into Vehicle',\n",
    "             'While Using Other Component/Controls Integral to Vehicle',\n",
    "             'Clock points',\n",
    "             'No Damage',\n",
    "             'Top',\n",
    "             'Undercarriage',\n",
    "             'Unknown',\n",
    "             'level_0',\n",
    "             'index']:\n",
    "                    if col in Accident_for_Model:\n",
    "                        del Accident_for_Model[col]\n",
    "# List the columns left in the df\n",
    "list(Accident_for_Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a look a at the data type on the Merged Data\n",
    "dtype_df=Accident_for_Model.dtypes.reset_index()\n",
    "dtype_df.columns=[\"Count\",\"ColumnType\"]\n",
    "dtype_df.groupby(\"ColumnType\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any observation value on the selected attributes that is reported as *Unknown*, *Other*, or *Not Reported* would be removed from the dataset. These values do not bring any value when it comes to predicting the response time of the paramedics, and are effectively a non-value for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns that might not be needed\n",
    "print(\"Unique values for 'route_signing_name':\" , Accident_for_Model.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'atmospheric_conditions_name':\" , Accident_for_Model.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'light_condition_name':\" , Accident_for_Model.light_condition_name.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes observations with an unknown informaiton in the route, atmospheric conditions and state name\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['route_signing_name'] != 'Unknown')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['route_signing_name'] != 'Other')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['atmospheric_conditions_name'] != 'Unknown')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['atmospheric_conditions_name'] != 'Other')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['atmospheric_conditions_name'] != 'Not Reported')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['light_condition_name'] != 'Unknown')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['light_condition_name'] != 'Other')]\n",
    "Accident_for_Model= Accident_for_Model[(Accident_for_Model['light_condition_name'] != 'Not Reported')]\n",
    "Accident_for_Model.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have confirmed that the undesired observations have been removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values for 'route_signing_name':\" , Accident_for_Model.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'atmospheric_conditions_name':\" , Accident_for_Model.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'light_condition_name':\" , Accident_for_Model.light_condition_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange colums\n",
    "Accident_for_Model=Accident_for_Model[['within 9 minutes NFPA standard','state_name','route_signing_name','atmospheric_conditions_name','light_condition_name']]\n",
    "list(Accident_for_Model)  # Check for the correct column sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section below will perform a one-hot encoding of the variables on the dataset. This is to prepare the data in such a way that can be use for our logistic regresion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding of the categorical data \"state_name\"\n",
    "tmp_state_df = pd.get_dummies(Accident_for_Model.state_name,prefix='state')\n",
    "#tmp_state_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"route_signing_name\"\n",
    "tmp_route_df = pd.get_dummies(Accident_for_Model.route_signing_name,prefix='route')\n",
    "#tmp_route_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"atmospheric_conditions_name\"\n",
    "tmp_atmos_df = pd.get_dummies(Accident_for_Model.atmospheric_conditions_name,prefix='atmos')\n",
    "#tmp_atmos_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"atmospheric_conditions_name\"\n",
    "tmp_light_df = pd.get_dummies(Accident_for_Model.light_condition_name, prefix='light')\n",
    "#tmp_atmos_df.head(20)\n",
    "\n",
    "Accident_for_Model = pd.concat((Accident_for_Model,tmp_state_df,tmp_route_df,tmp_atmos_df,tmp_light_df), axis=1) # add back into the dataframe\n",
    "list(Accident_for_Model)\n",
    "#delete the categorical variable columns\n",
    "del Accident_for_Model['state_name']\n",
    "del Accident_for_Model['route_signing_name']\n",
    "del Accident_for_Model['atmospheric_conditions_name']\n",
    "del Accident_for_Model['light_condition_name']\n",
    "\n",
    "#list(Accident_for_Model) # Check for the last colums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='OnTimeModel'></a>\n",
    "### Modeling and Evaluation 1\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Within NFPA standard Model\n",
    "\n",
    "We will compare our models based on precision.  We are using precision because we want to penalize false positives more. A high precision is better because this model would be used by emergency operators to communicate that the EMS will arrive within the standard time. You do not want to say they will arrive within the standard and they do not.  This could impact the decision made at the scene of the accident. Precision is defined as the number of true positives divided by the number of true positives plus the number of false positives. A false positive in this scenario is when the EMS does not arrive within the standard time, but it was classified as they did. A true positive is when the EMS is correctly classified as arriving with in the standard time.  \n",
    "\n",
    "$$ Precision =\\frac{True Positives}{True Positives + False Positives}$$\n",
    "\n",
    "###### Multi-Fatality Accidents Model\n",
    "\n",
    "F-measure is way to measure false positive and false negatives together. The true negative rate is not that important so there is no cost assigned to it. It is important to identify multi-fatality crashes versus single-fatality crashes because the EMS could respond accordingly and perhaps be more able to prevent deaths in such incidents in the future.  The F-measure is defined as the number of true positives multiplied by two divided by the number of true positives multiplied by two plus the number false negatives and the number of false positives. \n",
    "\n",
    "$$F-measure =\\frac{2(True Positives)}{2(True Positives) + False Positives + False Negatives }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within NFPA standard Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataSplit'></a>\n",
    "### Data Split and Cross Validation Setup\n",
    "**[Return](#DocIndex)**  \n",
    "\n",
    "We will be splitting the dataset  into a Training and Test set for the models. The split is going to be 80 % for training and the other 20 % for testing. The ratio used is accepted split in the research community, and we did not see any reason to deviate from this ratio. A Cross Validation of ten fold would be performed to validate the models. \n",
    "\n",
    "* Binary Response: *\"within 9 minutes NFPA standard\"*\n",
    "\n",
    "|Value|Description|\n",
    "|-----|:-----------|\n",
    "|0| Time of arrival > 9 minutes|\n",
    "|1| Time of arrival <=9 minutes|\n",
    "\n",
    "* To ensure that we use the same randomly-selected test and training sets each time we perform the cross-validation, we have specifically set a seed for our random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "OnTime_lr_clf = LogisticRegression(penalty='l2', C=1, class_weight=None) # get object\n",
    "modelPrecTestResults = pd.DataFrame() # This will store all the Precision results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set into Train and Test Sets.  \n",
    "The split uses a stratify strategy, in this way we get the same ratio of on-time and non-on-time on both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the Dataming Notbooks. Logistic Regression Notbook 4.\n",
    "#URL: https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'within 9 minutes NFPA standard' in Accident_for_Model:\n",
    "    y = Accident_for_Model['within 9 minutes NFPA standard'].values # get the labels we want\n",
    "    del Accident_for_Model['within 9 minutes NFPA standard'] # get rid of the class label\n",
    "    X = Accident_for_Model.values # use everything else to predict!\n",
    "\n",
    "#split Data into Test and Train data\n",
    "xTrain, Xtest, yTrain, yTest=train_test_split(X,y,test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "#scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(xTrain)\n",
    "X_train_scaled = scl_obj.transform(xTrain) # apply to training\n",
    "X_test_scaled = scl_obj.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the cross validation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 10  #number of Cross Validation folds\n",
    "num_instances = len(yTrain)\n",
    "\n",
    "# Cross Validation Object\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2,\n",
    "                         random_state=0)\n",
    "                         \n",
    "print(xTrain) # This prints all the dependant variables\n",
    "print(cv_object) # This print the Data split object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the 10-fold cross validation is indicated above. This value is using the selected parameter values described earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LogRegMod'></a>\n",
    "\n",
    "### Logistic Regression using Grid Search\n",
    "**[Return](#DocIndex)**\n",
    "\n",
    "On this section we will perform a serch for the best model using *Grid Search*. As per the previous model were the parameter values used to be fixed, in this section a range of parameters is given, and the search algorithm will iterate through all parameter conbinations.\n",
    "\n",
    "In this search we would go through 64 possible model combinations. From these model combinations, the algorithm will pick the one with the highest accuracy. \n",
    "\n",
    "The search parameter matrix will include:\n",
    "* **Penalty:** L2. This remains fixed, since solver 'sag' only takes L2 penalties.\n",
    "* **C (Cost):** It will test eight values: (0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000)\n",
    "* **Random State**: It will stay at 0. This is just the random seed. \n",
    "* **Solver:** Two modes will be tested under this parameter: 'sag','liblinear'. These are the algorithm for the optimzation problem. The first algorithm is optimized for large datasets, the second is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the notebook 'ComparingSegregatedHighSchoolCampuses.ipynb' to make a grid search for the best model\n",
    "#URL:https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', None]\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['sag','liblinear']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=OnTime_lr_clf\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_object # KFolds = 10\n",
    "                   , scoring='precision')\n",
    "\n",
    "# Perform the seaarch throught all the parameters in the parameters dictionary\n",
    "regGridSearch.fit(X_train_scaled, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the display for the parameters for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diplay the top model parameters\n",
    "print(regGridSearch.best_estimator_)\n",
    "\n",
    "# Display the Best Score of the iteration search\n",
    "print('\\nThe best precision score from the search is:', regGridSearch.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grid Search has obtained optimal parameters from the parameter matrix. These parameters would be stored in the **OntimeClassifierEst**. This object contains the model with the highest precision from the grid search.\n",
    "\n",
    "Next, the model with the optimal parameters would be used with a cross validation of ten fold. The results of the cross validation would be used to compare the performance of the models.\n",
    "\n",
    "The main differences betweem the two approachs are:  \n",
    "\n",
    "|Parameter|Grid Search|\n",
    "|---------|:---------:|\n",
    "|class_weight|None|\n",
    "|Cost (C) | 0.0001 |\n",
    "|Solver| liblinear|\n",
    "|Ten Fold Avg Accuracy| 0.695675 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Use the best parameters for our Linear Regression object\n",
    "OntimeLinClassifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "bestLinScores = cross_validate(OntimeLinClassifierEst,X_train_scaled,yTrain,scoring=['accuracy','precision','recall'], cv=cv_object, return_train_score=True)\n",
    "\n",
    "\n",
    "# grab the results from the dictionary into a dataframe\n",
    "cvScoreResult = pd.DataFrame()\n",
    "cvScoreResult['Accuracy'] = bestLinScores['test_accuracy']\n",
    "cvScoreResult['Precision'] = bestLinScores['test_precision']\n",
    "cvScoreResult['Recall'] = bestLinScores['test_recall']\n",
    "modelPrecTestResults['LinearRegression'] = bestLinScores['test_precision']\n",
    "\n",
    "print('Cross Validation Fold -- Mean Error Scores')\n",
    "print(cvScoreResult)\n",
    "\n",
    "avgAccuracy = bestLinScores['test_accuracy'].mean()\n",
    "avgPrecision = bestLinScores['test_precision'].mean()\n",
    "avgRecall = bestLinScores['test_recall'].mean()\n",
    "\n",
    "\n",
    "avgAccStr = \"\\nAverage accuracy for all cv folds is: \\t {avgAccuracy:.5}\"\n",
    "avgPrcStr = \"Average precision for all cv folds is: \\t {avgPrecision:.5}\"\n",
    "avgRecStr = \"Average recall for all cv folds is: \\t {avgRecall:.5}\"\n",
    "\n",
    "print(avgAccStr.format(avgAccuracy=avgAccuracy))\n",
    "print(avgPrcStr.format(avgPrecision=avgPrecision))\n",
    "print(avgRecStr.format(avgRecall=avgRecall))\n",
    "print('*********************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would try the model using the test data set, to determine the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Grid Search\n",
    "OntimeLinClassifierEst.fit(X_train_scaled,yTrain)\n",
    "y_hat_SearchGrid = OntimeLinClassifierEst.predict(X_test_scaled)\n",
    "y_hat_SearchGrid_score =  OntimeLinClassifierEst.predict_proba(X_test_scaled)\n",
    "conf_SearchGrid=mt.confusion_matrix(yTest,y_hat_SearchGrid)\n",
    "acc_SearchGrid = mt.accuracy_score(yTest,y_hat_SearchGrid)\n",
    "prec_SearchGrid = mt.precision_score(yTest,y_hat_SearchGrid)\n",
    "\n",
    "\n",
    "print (\"Precision with Seach Grid Parameters:\", prec_SearchGrid)\n",
    "print (\"Confusion matrix for Logistic Regression with Grid Seach Parameters\")\n",
    "print(pd.DataFrame(mt.confusion_matrix(yTest,y_hat_SearchGrid),\n",
    "             columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model applied on the test data is 0.0176 worst. This tells us that the new test data is very close to the training data, and that the model is consistent for the test data. Also, the precision value for the test data is suggesting that the model when predicting that the paramedics are on time, they have a 67% chance they will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TreeMod'></a>\n",
    "### Tree Ensemble Comparisons setup\n",
    "\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already on a cell above this cell can be removed\n",
    "\n",
    "# Code to run through the cross validation loop and set the training and testing variable for one single iteration \n",
    "#Code addapted from the Dataming Notbooks. Logistic Regression and SVM Notbook 4\n",
    "#URL: https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#for train_indices, test_indices in cv_object.split(X,y): \n",
    "    \n",
    "#    X_train = X[train_indices]\n",
    "#    y_train = y[train_indices]\n",
    "    \n",
    "#    X_test = X[test_indices]\n",
    "#    y_test = y[test_indices]\n",
    "#    xTrain, yTrain\n",
    "#scale attributes by the training set\n",
    "#scl_obj = StandardScaler()\n",
    "#scl_obj.fit(X_train)\n",
    "#X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "#X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_estimators = 50\n",
    "# lets train some trees\n",
    "clf_array = [\n",
    "    #('Tree',               DecisionTreeClassifier()),\n",
    "    ('Random Trees',       RandomForestClassifier(n_jobs=-1))\n",
    "    #('Extra Random Trees', ExtraTreesClassifier(n_estimators=num_estimators,min_samples_split=2)),\n",
    "    #('Boosted Tree',       GradientBoostingClassifier(n_estimators=num_estimators)), #takes a long time\n",
    "    ]\n",
    "\n",
    "#param for classifier   \n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [100, 300],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 20],\n",
    "    'random_state':[0]\n",
    "}\n",
    "\n",
    "\n",
    "    \n",
    "for clf in clf_array: \n",
    "    print(\"Grid Search for :\", clf[0])\n",
    "    grid_search = GridSearchCV(clf[1], param_grid, scoring='precision', refit='precision_score',\n",
    "                       cv=cv_object, return_train_score=True, n_jobs=8,verbose=1)\n",
    "    grid_search.fit(X_train_scaled, yTrain)\n",
    "    OntimeTreeClassifierEst = grid_search.best_estimator_\n",
    "    y_hat = OntimeTreeClassifierEst.predict(X_test_scaled)\n",
    "    \n",
    "    print('Best params for {}'.format('precision_score'))\n",
    "    print(grid_search.best_params_)\n",
    "    print('\\nThe best precision score from the search is:', grid_search.best_score_ )\n",
    "        # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format('precision_score'))\n",
    "    print(pd.DataFrame(confusion_matrix(yTest, y_hat),\n",
    "             columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    \n",
    "    print(\"{} Precision Score for the Test Data\".format(clf[0]) ,mt.precision_score(yTest, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the best parameters for our Tree Class object\n",
    "\n",
    "\n",
    "bestScores = cross_validate(OntimeTreeClassifierEst,X_train_scaled,yTrain,scoring=['accuracy','precision','recall'], cv=cv_object, return_train_score=True)\n",
    "\n",
    "\n",
    "# grab the results from the dictionary into a dataframe\n",
    "cvScoreResult = pd.DataFrame()\n",
    "cvScoreResult['Accuracy'] = bestScores['test_accuracy']\n",
    "cvScoreResult['Precision'] = bestScores['test_precision']\n",
    "cvScoreResult['Recall'] = bestScores['test_recall']\n",
    "modelPrecTestResults['TreeModel'] = bestScores['test_precision']\n",
    "\n",
    "print('Cross Validation Fold -- Mean Error Scores')\n",
    "print(cvScoreResult)\n",
    "\n",
    "avgAccuracy = bestScores['test_accuracy'].mean()\n",
    "avgPrecision = bestScores['test_precision'].mean()\n",
    "avgRecall = bestScores['test_recall'].mean()\n",
    "\n",
    "\n",
    "avgAccStr = \"\\nAverage accuracy for all cv folds is: \\t {avgAccuracy:.5}\"\n",
    "avgPrcStr = \"Average precision for all cv folds is: \\t {avgPrecision:.5}\"\n",
    "avgRecStr = \"Average recall for all cv folds is: \\t {avgRecall:.5}\"\n",
    "\n",
    "print(avgAccStr.format(avgAccuracy=avgAccuracy))\n",
    "print(avgPrcStr.format(avgPrecision=avgPrecision))\n",
    "print(avgRecStr.format(avgRecall=avgRecall))\n",
    "print('*********************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='KNNMod'></a>\n",
    "### K-Nearest Neighbors\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and predictions: \n",
    "#source: https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  #Initialize the value for K\n",
    "classifier.fit(X_train_scaled, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param for classifier   \n",
    "KNNclassifier = KNeighborsClassifier() \n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 5, 10], \n",
    "    #'random_state':[0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(KNNclassifier, param_grid, scoring='precision', refit='precision_score',\n",
    "                   cv=cv_object, return_train_score=True, n_jobs=8,verbose=1)\n",
    "grid_search.fit(X_train_scaled, yTrain)\n",
    "OntimeKNNClassifierEst = grid_search.best_estimator_\n",
    "y_hat = OntimeKNNClassifierEst.predict(X_test_scaled)\n",
    "\n",
    "print('Best params for {}'.format('precision_score'))\n",
    "print(grid_search.best_params_)\n",
    "print('\\nThe best precision score from the search is:', grid_search.best_score_ )\n",
    "    # confusion matrix on the test data.\n",
    "print('\\nConfusion matrix of KNN optimized for {} on the test data:'.format('precision_score'))\n",
    "print(pd.DataFrame(confusion_matrix(yTest, y_hat),\n",
    "         columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "\n",
    "print(\"{} Precision Score for the Test Data\".format('KNN') ,mt.precision_score(yTest, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions out of the test data\n",
    "y_pred = OntimeKNNClassifierEst.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Algorithm, For evaluating an algorithm, confusion matrix, precision, recall and f1 score are the most commonly used metrics.\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print('Confusion Matrix for KNN: \\n', pd.DataFrame(confusion_matrix(yTest, y_pred),\n",
    "             columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "print(classification_report(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# We randomly chose 5 as the K value and it may not be 100% accurate.\n",
    "#One way to help you find the best value of K is to plot the graph of K value and \n",
    "#the corresponding error rate for the dataset.\n",
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):  \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_scaled, yTrain)\n",
    "    pred_i = knn.predict(X_test_scaled)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script executes a loop from 1 to 40. In each iteration the mean error for predicted values of test set is calculated and the result is appended to the error list.\n",
    "\n",
    "The next step is to plot the error values against K values. Execute the following script to create the plot as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows the Least Mean error is for the K-value 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the best parameters for our K-Nearest Neighbors\n",
    "\n",
    "#OntimeKNNClassifierEst.fit(X_train_scaled, yTrain) # From Grid Search\n",
    "\n",
    "bestScores = cross_validate(OntimeKNNClassifierEst,X_train_scaled, yTrain,scoring=['accuracy','precision','recall'], cv=cv_object, return_train_score=True)\n",
    "\n",
    "\n",
    "# grab the results from the dictionary into a dataframe\n",
    "cvScoreResult = pd.DataFrame()\n",
    "cvScoreResult['Accuracy'] = bestScores['test_accuracy']\n",
    "cvScoreResult['Precision'] = bestScores['test_precision']\n",
    "cvScoreResult['Recall'] = bestScores['test_recall']\n",
    "modelPrecTestResults['kNN'] = bestScores['test_precision']\n",
    "\n",
    "print('Cross Validation Fold -- Mean Error Scores')\n",
    "print(cvScoreResult)\n",
    "\n",
    "avgAccuracy = bestScores['test_accuracy'].mean()\n",
    "avgPrecision = bestScores['test_precision'].mean()\n",
    "avgRecall = bestScores['test_recall'].mean()\n",
    "\n",
    "\n",
    "avgAccStr = \"\\nAverage accuracy for all cv folds is: \\t {avgAccuracy:.5}\"\n",
    "avgPrcStr = \"Average precision for all cv folds is: \\t {avgPrecision:.5}\"\n",
    "avgRecStr = \"Average recall for all cv folds is: \\t {avgRecall:.5}\"\n",
    "\n",
    "print(avgAccStr.format(avgAccuracy=avgAccuracy))\n",
    "print(avgPrcStr.format(avgPrecision=avgPrecision))\n",
    "print(avgRecStr.format(avgRecall=avgRecall))\n",
    "print('*********************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='OnTimeComp'></a>\n",
    "### Model Comparison for Paramedics On-time Arraival\n",
    "**[Return](#DocIndex)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section can be use for the statistical analysis\n",
    "modelPrecTestResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPrecTestResults.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Code addapted from the notebook '06. Clasification.ipynb' \n",
    "#https://github.com/eclarson/DataMiningNotebooks/blob/master/06.%20Classification.ipynb\n",
    "seaborn.set_palette(\"dark\")\n",
    "# code manipulated from http://scikit-learn.org/stable/auto_examples/plot_roc.html\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Compute ROC curve for a subset of interesting classes\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in np.unique(yTest):\n",
    "    fpr[i], tpr[i], _ = mt.roc_curve(yTest, y_hat_SearchGrid_score[:, i], pos_label=i)\n",
    "    roc_auc[i] = mt.auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(fpr[1], tpr[1], label='Paramedic On-time class {0} with {1} instances (area = {2:0.2f})'\n",
    "                                   ''.format(1, sum(yTest==1), roc_auc[1]))\n",
    "\n",
    "    \n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart by weight for the logistic regresion\n",
    "import scipy.stats as st\n",
    "weights=OntimeLinClassifierEst.coef_.ravel()\n",
    "variable_names = Accident_for_Model.columns\n",
    "inRegFt_df = pd.DataFrame({'variables':variable_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "\n",
    "inRegFt_df.sort_values(by='weights', inplace=True, ascending=False )\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "weights = pd.Series(inRegFt_df['weights'].values,index=inRegFt_df['variables'])\n",
    "ax = weights.plot(kind='bar', figsize=(15,10))\n",
    "\n",
    "ax.set_title(\"Feature Correlations\")\n",
    "ax.set_ylabel(\"Coefficient Magnitude\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MultiFatality'></a>\n",
    "## Multi-Fatality Accidents\n",
    "**[Return](#DocIndex)**  \n",
    "\n",
    "For our second task, we are interested in determining if there are factors that are more strongly related to multi-fatality crashes versus single-fatality crashes. This is a very relevant problem given our domain space: if emergency services could reasonably predict, based on some factors, if a given crash is going to have multiple fatalities, they could respond accordingly and perhaps be more able to prevent deaths in such incidents in the future. We will therefore investigate the data in several ways, in an attempt to answer the question of whether or not some factors are more likely to be associated with a multi-fatality accident over others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preperation for Multiple Fatalities Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the Multiple_Fatalities classification to be the dependent variable for Model 2. This will be binary using ‘1’ to indicate that there is more than 1 fatality in the accident and ‘0’, if it is not a multiple fatality accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the binary variable for clasificaiton 'Multiple_Fatalities'\n",
    "Accident_df_2['Multiple_Fatalities'] = np.where(Accident_df_2['number_of_fatalities'] > 1,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scatter matrix for damage variables and the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a data frame of only variables that we want to examine visually  \n",
    "Accident_forScatter=Accident_df_2[['Multiple_Fatalities','Clock points','No Damage','Top','Undercarriage','Unknown']]\n",
    "\n",
    "            \n",
    "# Dislplays the data types of the variables\n",
    "Accident_forScatter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "ax = scatter_matrix(Accident_forScatter,figsize=(15, 10),diagonal='kde')\n",
    "#y labels\n",
    "[plt.setp(item.yaxis.get_label(), 'size', 10,  rotation=0) for item in ax.ravel()]\n",
    "\n",
    "#x labels\n",
    "[plt.setp(item.xaxis.get_label(), 'size', 10, rotation=90) for item in ax.ravel()]\n",
    "\n",
    "#need to offset label when rotating to prevent overlap of figure\n",
    "[s.get_yaxis().set_label_coords(-1.5,0.5) for s in ax.reshape(-1)]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scatter matrix for distract variables and the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a data frame of only variables that we want to examine visually  \n",
    "Accident_forScatter=Accident_df_2[['Multiple_Fatalities',\n",
    "                                   'By a Moving Object in Vehicle',\n",
    "                                   'By Other Occupant(s)',\n",
    "                                   'Careless/Inattentive',\n",
    "                                   'Distracted by Outside Person, Object or Event',\n",
    "                                   'Distraction (Distracted), Details Unknown',\n",
    "                                   'Distraction/Inattention','Eating or Drinking',\n",
    "                                   'Inattention (Inattentive), Details Unknown',\n",
    "                                   'Looked But Did Not See',\n",
    "                                   'Lost In Thought/Day Dreaming',\n",
    "                                   'No Driver Present/Unknown if Driver Present',\n",
    "                                   'Not Distracted','Not Reported',\n",
    "                                   'Other Cellular Phone Related',\n",
    "                                   'Other Distraction',\n",
    "                                   'Smoking Related',\n",
    "                                   'Unknown if Distracted',\n",
    "                                   'While Adjusting Audio or Climate Controls',\n",
    "                                   'While Manipulating Cellular Phone',\n",
    "                                   'While Talking or Listening to Cellular Phone',\n",
    "                                   'While Using or Reaching For Device/Object Brought Into Vehicle',\n",
    "                                   'While Using Other Component/Controls Integral to Vehicle']]\n",
    "\n",
    "            \n",
    "# Dislplays the data types of the variables\n",
    "Accident_forScatter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "ax = scatter_matrix(Accident_forScatter,figsize=(15, 10),diagonal='kde')\n",
    "#y labels\n",
    "[plt.setp(item.yaxis.get_label(), 'size', 10,  rotation=0) for item in ax.ravel()]\n",
    "\n",
    "#x labels\n",
    "[plt.setp(item.xaxis.get_label(), 'size', 10, rotation=90) for item in ax.ravel()]\n",
    "\n",
    "#need to offset label when rotating to prevent overlap of figure\n",
    "[s.get_yaxis().set_label_coords(-1.5,0.5) for s in ax.reshape(-1)]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "num_estimators = 50\n",
    "# lets train some trees\n",
    "clf_array = [\n",
    "    ('Stump',              DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)),\n",
    "    ('Tree',               DecisionTreeClassifier()),\n",
    "    ('Random Trees',       RandomForestClassifier(max_depth=50, n_estimators=num_estimators)),\n",
    "    ('Extra Random Trees', ExtraTreesClassifier(n_estimators=num_estimators,min_samples_split=2)),\n",
    "    ('Boosted Tree',       GradientBoostingClassifier(n_estimators=num_estimators)), #takes a long time\n",
    "    ]\n",
    "\n",
    "for clf in clf_array:\n",
    "    acc = cross_val_score(clf[1],X,y)\n",
    "    print (clf[0], acc.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
